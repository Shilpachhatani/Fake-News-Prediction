{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867aead4-0998-4247-aaaa-a65ed2c91d18",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Develop a machine learning model to classify whether a news article is real or fake based on its content using NLP techniques.\n",
    "##### **Objectives:**\n",
    "- Clean and preprocess text data\n",
    "- Convert it into numerical format using TF-IDF\n",
    "- Train a Logistic Regression classifier/ Random Forest\n",
    "- Evaluate using Accuracy, Precision, Recall, F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e0e624-d00c-4c34-a82b-4966747ac0e5",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec0721-12fb-4740-870a-af44f294cf8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bd1dc-1107-49d7-94db-7454e4a03f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4f779-69b2-4312-ae32-3dbbd794b015",
   "metadata": {},
   "source": [
    "### Load and Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27072c3a-9dd2-4892-a386-794c3ee2f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "true_df = pd.read_csv(\"../data/True.csv\")\n",
    "fake_df = pd.read_csv(\"../data/Fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f494ef-dd52-4dc9-924a-b281409ddc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels\n",
    "true_df['label'] = 1  # Real\n",
    "fake_df['label'] = 0  # Fake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fed633-d7a9-4d18-8e6f-3b537a0d0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Title and Text\n",
    "data = pd.concat([true_df, fake_df], axis=0).reset_index(drop=True)\n",
    "data['content'] = data['title'] + \" \" + data['text']\n",
    "\n",
    "data.head()\n",
    "#Both title and text are informative. Merging them into a single content column gives the model a better understanding of the article’s context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70b188-8339-483c-bdb9-a48100dbedb9",
   "metadata": {},
   "source": [
    "### Preprocess the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2095cb-4742-4c9e-b32c-ab0838ce2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stopwords_set = {\n",
    "    'the', 'a', 'is', 'in', 'and', 'to', 'of', 'that', 'it', 'on',\n",
    "    'was', 'he', 'she', 'for', 'with', 'as', 'by', 'at', 'from'\n",
    "}\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    filtered = [stemmer.stem(word) for word in words if word not in stopwords_set]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "data['cleaned_content'] = data['content'].apply(clean_text)\n",
    "\n",
    "#This prepares the text for vectorization:\n",
    "#it removes noise (punctuation, numbers),converts words to root form (stemming) and removes common, meaningless words (stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd53eef-9630-4be0-ab5c-b46e23954e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb0cce9-f2e6-4c51-999f-d16f1bbd20f5",
   "metadata": {},
   "source": [
    "### Vectorize Text (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1e980-d138-4cc5-9261-5fb2525299b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert cleaned text into sparse matrix (memory efficient)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(data['cleaned_content'])  \n",
    "y = data['label'].values\n",
    "\n",
    "# TF-IDF captures word importance across the corpus.\n",
    "#Many fake articles may use overused terms (e.g., \"shocking\", \"breaking\", \"alert\") or poor grammar.\n",
    "#Real articles have formal structure and named sources.\n",
    "#So, TF-IDF helps to classify those while ignoring common words so that model learns strong patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82f1ee9-2e59-47ab-9bc1-256352d7f9bc",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e79ea-7d1a-43a6-9aa2-4f913f7aae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc2f06a-022a-4db0-9a86-5110a9878fcd",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "Using Logistic Regression and Random Forest to test which works best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20cf40b-3d47-477a-aab6-938c90611a29",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ecb18-e80c-44c0-a624-caee5279d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "lr_report = classification_report(y_test, lr_pred, target_names=[\"Fake\", \"Real\"], output_dict=True)\n",
    "\n",
    "print(\" Logistic Regression Evaluation\")\n",
    "print(f\"Accuracy: {lr_accuracy * 100:.2f}%\\n\")\n",
    "print(classification_report(y_test, lr_pred, target_names=[\"Fake\", \"Real\"]))\n",
    "\n",
    "# Get confusion matrix\n",
    "cm = confusion_matrix(y_test, lr_pred)\n",
    "\n",
    "# Plot using seaborn heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Fake\", \"Real\"], yticklabels=[\"Fake\", \"Real\"])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title(' Logistic Regression - Confusion Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b108bc-9acc-4469-96f6-30d04a590b71",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- Accuracy: 98.88%\n",
    "- Fake News: 4585 correct, 65 missed\n",
    "- Real News: 4294 correct, 36 wrongly marked as fake\n",
    "- Total mistakes: Only 101 out of 8980\n",
    "- Precision: 99% – Predictions are mostly correct\n",
    "- Recall: 99% – Very few fake/real articles missed\n",
    "- F1-Score: 99% – Excellent balance and consistency\n",
    "##### **Conclusion:**\n",
    "Logistic Regression Model is highly accurate and reliable, with very few errors in both fake and real news detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430a2c8-8bf9-4b0a-9267-f0ef53cd9ad3",
   "metadata": {},
   "source": [
    "### Train Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a5122-bc86-4042-85a6-a26d0e9e4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_report = classification_report(y_test, rf_pred, target_names=[\"Fake\", \"Real\"], output_dict=True)\n",
    "\n",
    "print(\" Random Forest Evaluation\")\n",
    "print(f\"Accuracy: {rf_accuracy * 100:.2f}%\\n\")\n",
    "print(classification_report(y_test, rf_pred, target_names=[\"Fake\", \"Real\"]))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, rf_pred)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=[\"Fake\", \"Real\"], yticklabels=[\"Fake\", \"Real\"])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Random Forest - Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47446ca9-a860-4714-8e5c-5cef850a5b16",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- Accuracy: 99.65%\n",
    "- Fake News: 4635 correct, 15 missed\n",
    "- Real News: 4314 correct, 16 wrongly marked as fake\n",
    "- Total mistakes: Only 31 out of 8980\n",
    "- Precision: 100% – Predictions are almost always correct\n",
    "- Recall: 100% – Very few fake/real articles missed\n",
    "- F1-Score: 100% – Perfect balance and consistency\n",
    "##### **Conclusion:**\n",
    "The Random Forest model performs exceptionally well, with near-perfect accuracy and no significant errors in classifying fake and real news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383a24c-3f9b-423f-8fd3-fc5cabe338bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c4405dd-7be4-43cf-b511-768d373bd8bc",
   "metadata": {},
   "source": [
    "### Final Conclusion\n",
    "Both models performed exceptionally well:\n",
    "\n",
    "**Logistic Regression** achieved **98.88%** accuracy, is faster, and easier to interpret. It's ideal for real-time applications and works well with clean, structured text.\n",
    "\n",
    "**Random Forest** achieved a slightly higher **99.65%** accuracy, with better handling of complex patterns and more robustness to noisy or nonlinear data, though it takes longer to train.\n",
    "\n",
    "While the performance difference is not very large, we chose to proceed with the Random Forest model due to its higher accuracy and better generalization on more complex or potentially noisy datasets. This makes it a more reliable choice for ensuring consistent performance in varied real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d23a24-02b9-4ff8-8db9-dae16287589f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a580ce8-4e42-4209-864d-b4f39e35d45b",
   "metadata": {},
   "source": [
    "### Usage Example – Predict New Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6719acea-23c5-4c26-807b-1d01788e6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predict whether a given news article is real or fake.\n",
    "    Args:\n",
    "        text (str): The news article (title + content).\n",
    "        model: Trained classification model.\n",
    "        vectorizer: Trained TF-IDF vectorizer.\n",
    "    Returns:\n",
    "        str: \"Real\" or \"Fake\"\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(text)  # Apply same preprocessing\n",
    "    vectorized = vectorizer.transform([cleaned]).toarray()  # Vectorize\n",
    "    prediction = model.predict(vectorized)[0]  # Predict\n",
    "    return \"Real\" if prediction == 1 else \"Fake\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7c3e0b-eae2-44a5-ac3e-04db430f28a4",
   "metadata": {},
   "source": [
    "### Try with Example Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3725fb-dd40-4a6b-9fed-c8e0e858d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input (you can change this!)\n",
    "sample_news = \"\"\"\n",
    "President announces new economic plan to support small businesses\n",
    "and reduce interest rates amidst inflation concerns. The plan includes\n",
    "tax breaks and grants over the next fiscal year.\n",
    "\"\"\"\n",
    "\n",
    "# Predict with both models\n",
    "\n",
    "rf_result = predict_news(sample_news, rf_model, vectorizer)\n",
    "\n",
    "print(f\"Random Forest says: {rf_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5278ed-e847-4b34-ac34-291b041e9b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de196493-433b-4da9-ba9a-482084b467c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da7d25-22d8-4235-9de2-effc86d674f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64cebc-821f-444a-8863-299bcaf5e043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
